{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff38694c-68fd-42d8-b6dc-1a2e3a10eca2",
   "metadata": {},
   "source": [
    "# CC3M Similarity\n",
    "Before starting, please download the training and validation splits of CC3M from https://ai.google.com/research/ConceptualCaptions/download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935700a9-e0b1-451d-8f51-e5a818fba828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "from PIL import Image\n",
    "from PIL import ImageFile                                                      \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7acc860-2b7a-42a2-932e-82a1ae6e815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('Validation_GCC-1.1.0-Validation.tsv', sep='\\t', header=None, names=['caption', 'image_url'])\n",
    "trn_df = pd.read_csv('Train_GCC-training.tsv', sep='\\t', header=None, names=['caption', 'image_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1ef277-3bbc-4ee4-bda8-fb3f5ed37beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15840, 2), (3318333, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape, trn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b8f9d-4482-41a7-9448-386cd0afd16b",
   "metadata": {},
   "source": [
    "### Test Parallel Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2557865-05fe-4b52-b8d6-2ba17687e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalid_images_as_none(batch):\n",
    "    images = []\n",
    "    for image_url in batch[\"image_url\"]:\n",
    "        try:\n",
    "            image = Image.open(requests.get(image_url, stream=True, timeout=5).raw)\n",
    "        except Exception:\n",
    "            image = None\n",
    "        images.append(image)\n",
    "    batch[\"image\"] = images\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09f0c37-ea63-439e-a304-60213492d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = datasets.Dataset.from_pandas(val_df)\n",
    "dset = dset.with_transform(invalid_images_as_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debeac8-eee5-417d-b9ba-db110faf26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seq_times = []\n",
    "nd = 256\n",
    "\n",
    "start_time = time.time() \n",
    "for i, batch in enumerate(dset):\n",
    "    if i == nd:\n",
    "        break\n",
    "    end_time = time.time() \n",
    "    seq_times.append(end_time - start_time)\n",
    "    start_time = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d249fbf3-9119-4fac-8eec-2cf3e53f6433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 2.94 s, total: 4.86 s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs16_times = []\n",
    "bs = 16\n",
    "nd = 1024\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "\n",
    "item_count = 0\n",
    "start_time = time.time() \n",
    "for batch in loader:\n",
    "    item_count += len(batch['caption'])\n",
    "    \n",
    "    end_time = time.time() \n",
    "    bs16_times.append(end_time - start_time)\n",
    "    start_time = time.time() \n",
    "    \n",
    "    if item_count >= nd:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94c67a2-2a4b-4fb1-9d76-25c0b2ffcfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.37 s, sys: 5.07 s, total: 7.44 s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs32_times = []\n",
    "bs = 32\n",
    "nd = 1024\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "\n",
    "item_count = 0\n",
    "start_time = time.time() \n",
    "for batch in loader:\n",
    "    item_count += len(batch['caption'])\n",
    "    \n",
    "    end_time = time.time() \n",
    "    bs32_times.append(end_time - start_time)\n",
    "    start_time = time.time() \n",
    "    \n",
    "    if item_count >= nd:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9f7cb1-b17c-4e87-8489-9e3d6a749747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.57 s, sys: 16.4 s, total: 22 s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs64_times = []\n",
    "bs = 64\n",
    "nd = 1024\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "\n",
    "item_count = 0\n",
    "start_time = time.time() \n",
    "for batch in loader:\n",
    "    item_count += len(batch['caption'])\n",
    "    \n",
    "    end_time = time.time() \n",
    "    bs64_times.append(end_time - start_time)\n",
    "    start_time = time.time() \n",
    "    \n",
    "    if item_count >= nd:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d499ac8d-9ff0-44fc-b16a-3ace8eab1680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/Image.py\", line 712, in __getstate__\n",
      "    im_data = self.tobytes()  # load image first\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/Image.py\", line 755, in tobytes\n",
      "    self.load()\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/ImageFile.py\", line 288, in load\n",
      "    raise OSError(msg)\n",
      "OSError: image file is truncated (26 bytes not processed)\n",
      "/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 47.7 s, total: 1min 4s\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs128_times = []\n",
    "bs = 128\n",
    "nd = 1024\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "\n",
    "item_count = 0\n",
    "start_time = time.time() \n",
    "for batch in loader:\n",
    "    item_count += len(batch['caption'])\n",
    "    \n",
    "    end_time = time.time() \n",
    "    bs128_times.append(end_time - start_time)\n",
    "    start_time = time.time() \n",
    "    \n",
    "    if item_count >= nd:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8c7a1b-1520-4f57-9fa8-c855f7c39c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/Image.py\", line 712, in __getstate__\n",
      "    im_data = self.tobytes()  # load image first\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/Image.py\", line 755, in tobytes\n",
      "    self.load()\n",
      "  File \"/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/ImageFile.py\", line 288, in load\n",
      "    raise OSError(msg)\n",
      "OSError: image file is truncated (26 bytes not processed)\n",
      "/home/scahyawijaya/anaconda3/envs/env_indot0/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 1min 16s, total: 1min 41s\n",
      "Wall time: 6min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69384765625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bs = 128\n",
    "nb = 64\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "image_exist = []\n",
    "\n",
    "item_count = 0\n",
    "for batch in loader:\n",
    "    item_count += len(batch['caption'])\n",
    "    image_exist += map(lambda x: x is not None, batch['image'])\n",
    "    if item_count == bs * nb:\n",
    "        break\n",
    "sum(image_exist) / len(image_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "783ebfc7-9c66-4ced-964c-d36d9db41589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697.1393938064575"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(seq_times) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50b1ddea-63ac-4ab8-82b3-a40e309d2200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125.81549263000488, 1.9658670723438263, 97.05540823936462)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bs16_times), sum(bs16_times) / len(bs16_times), sum(bs16_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3efa2ec-6d66-4730-8dde-30646add788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87.29814529418945, 2.7280670404434204, 47.26372528076172)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bs32_times), sum(bs32_times) / len(bs32_times), sum(bs32_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b2c4b40-d354-4a0f-ba3c-9927f4efbc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148.8310990333557, 9.301943689584732, 77.15501260757446)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bs64_times), sum(bs64_times) / len(bs64_times), sum(bs64_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c02d3b2-d473-46bd-ab20-bf127b51d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275.9560577869415, 34.49450722336769, 58.863117694854736)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bs128_times), sum(bs128_times) / len(bs128_times), sum(bs128_times[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e925d84-dd67-4c6b-83c3-88e0cc706a39",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9172a5-8cb9-43d9-a72a-47c98fa8d56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/clip-ViT-B-32\").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ddd6f-6efa-4c98-81eb-f6da3b75af2f",
   "metadata": {},
   "source": [
    "# Load SEA-VQA & CVQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029defef-fe8b-4467-b18a-fa9c01058517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary activity depicted in the image?',\n",
       " 'choice_a': 'Gathering fruits',\n",
       " 'choice_b': 'Fishing',\n",
       " 'choice_c': 'Picking herbs',\n",
       " 'choice_d': 'Planting trees',\n",
       " 'correct_answer': 'c',\n",
       " 'image_path': 'https://ich.unesco.org/img/photo/thumb/16712-HUG.jpg',\n",
       " 'image_page': 'https://ich.unesco.org/en/photo-pop-up-00973?photoID=16712',\n",
       " 'copyright': 'Photograph: Ganesh Ahsha Dalila© Dwi Ranny Pertiwi Zarman, Indonesia, 2022'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sea_vqa_dataset = load_dataset('wit543/sea-vqa')\n",
    "sea_vqa_dataset['indonesia'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39f55d1-46d6-4580-86ef-1844041ad33c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=154x215>,\n",
       " 'ID': '5865939224275596310_1',\n",
       " 'Subset': \"('Sundanese', 'Indonesia')\",\n",
       " 'Question': 'Naon prestasina inohong dina gambar?',\n",
       " 'Translated Question': 'What is the achievement of the figure in the picture?',\n",
       " 'Options': ['Gubernur Jawa Barat',\n",
       "  'Wali kota Bandung',\n",
       "  'Gubernur DKI Jakarta',\n",
       "  'Wali kota Tasik'],\n",
       " 'Translated Options': ['Governor of West Java',\n",
       "  'Mayor of Bandung',\n",
       "  'Governor of the Special Capital Region of Jakarta',\n",
       "  'Mayor of Tasik'],\n",
       " 'Label': -1,\n",
       " 'Category': 'Public Figure and pop culture',\n",
       " 'Image Type': 'External',\n",
       " 'Image Source': 'https://upload.wikimedia.org/wikipedia/commons/0/01/Mayor_of_Bandung_Dada_Rosada.jpg',\n",
       " 'License': 'Public domain'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvqa_dataset = load_dataset('afaji/cvqa')\n",
    "\n",
    "cvqa_sea_subsets = [\n",
    "    \"('Indonesian', 'Indonesia')\",\n",
    "    \"('Malay', 'Malaysia')\",\n",
    "    \"('Javanese', 'Indonesia')\",\n",
    "    \"('Minangkabau', 'Indonesia')\",\n",
    "    \"('Sundanese', 'Indonesia')\",\n",
    "    \"('Chinese', 'Singapore')\"\n",
    "]\n",
    "cvqa_dataset_filt = cvqa_dataset['test'].filter(lambda x: x['Subset'] in cvqa_sea_subsets, num_proc=32)\n",
    "cvqa_dataset_filt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b046fc45-b04c-4168-aa80-e6d8dddb6112",
   "metadata": {},
   "source": [
    "### Extract SEA-VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617777f3-59ad-4da0-b8d0-d28f2f5901b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 304/304 [16:08<00:00,  3.18s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 752/752 [30:48<00:00,  2.46s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [02:14<00:00,  1.87s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [05:58<00:00,  1.90s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 153/153 [07:07<00:00,  2.80s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:04<00:00,  2.03s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 184/184 [05:20<00:00,  1.74s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [12:35<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 8s, sys: 55 s, total: 26min 3s\n",
      "Wall time: 1h 21min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract Text & Image Features from SEA-VQA\n",
    "\n",
    "sea_vqa_images_filt = []\n",
    "sea_vqa_images_embed = []\n",
    "sea_vqa_caption = []\n",
    "sea_vqa_culture = []\n",
    "for key in sea_vqa_dataset.keys():\n",
    "    for row in tqdm(sea_vqa_dataset[key]):\n",
    "        try:\n",
    "            img_opened = Image.open(requests.get(row['image_path'], stream=True).raw)\n",
    "            sea_vqa_images_embed.append(model.encode(img_opened))\n",
    "            sea_vqa_images_filt.append(img_opened)\n",
    "            if row['correct_answer'] in ['a', 'b', 'c', 'd']:\n",
    "                sea_vqa_caption.append(row['question'] + \" \" + row['choice_' + row['correct_answer']])\n",
    "            else:\n",
    "                sea_vqa_caption.append(row['question'])\n",
    "            sea_vqa_culture.append(key)\n",
    "        except:\n",
    "            print(row)\n",
    "pickle.dump((sea_vqa_images_filt, sea_vqa_images_embed, sea_vqa_caption, sea_vqa_culture), open('sea_vqa.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60562a9f-0cd0-4001-8307-2469f125e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sea_vqa_images_filt, sea_vqa_images_embed, sea_vqa_caption, sea_vqa_culture) = pickle.load(open('sea_vqa.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1201813-35cf-4f05-9f68-b0873553b38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 1999, 1999, 1999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sea_vqa_images_filt), len(sea_vqa_images_embed), len(sea_vqa_caption), len(sea_vqa_culture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c7211-2570-41ff-8c53-1205fa6327f9",
   "metadata": {},
   "source": [
    "### Extract CVQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46372770-abce-476e-a581-68d7728ac8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1687/1687 [11:04<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 58s, sys: 3min 19s, total: 27min 18s\n",
      "Wall time: 13min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract Text & Image Features from CVQA\n",
    "\n",
    "cvqa_images_filt = []\n",
    "cvqa_images_embed = []\n",
    "cvqa_caption = []\n",
    "cvqa_culture = []\n",
    "for row in tqdm(cvqa_dataset_filt):\n",
    "    try:\n",
    "        cvqa_images_embed.append(model.encode(row['image']))\n",
    "        cvqa_images_filt.append(row['image'])\n",
    "        cvqa_caption.append(row['Translated Question'] + \" \" + ', '.join(row['Translated Options']))\n",
    "        cvqa_culture.append(eval(cvqa_dataset_filt[0]['Subset'])[0])\n",
    "    except:\n",
    "        print(row)\n",
    "pickle.dump((cvqa_images_filt, cvqa_images_embed, cvqa_caption, cvqa_culture), open('cvqa.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4faebd3-ae12-4fa4-a785-d651d8285919",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cvqa_images_filt, cvqa_images_embed, cvqa_caption, cvqa_culture) = pickle.load(open('cvqa.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93834bd0-ed76-46f2-813b-e24d1e42423f",
   "metadata": {},
   "source": [
    " ### Extract CC3M Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6fb381-c494-4ba3-b168-a59fe812e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "1it [00:28, 28.71s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "72it [02:36,  1.85s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "248it [04:40,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 36s, sys: 1min 41s, total: 16min 17s\n",
      "Wall time: 4min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract Text & Image Features from CC3M\n",
    "bs = 64\n",
    "cc3m_val_images_embed = []\n",
    "cc3m_val_images_filt = []\n",
    "cc3m_val_caption = []\n",
    "\n",
    "def invalid_images_as_none(batch):\n",
    "    images = []\n",
    "    for image_url in batch[\"image_url\"]:\n",
    "        try:\n",
    "            image = Image.open(requests.get(image_url, stream=True, timeout=8).raw).convert('RGB')\n",
    "        except Exception:\n",
    "            image = None\n",
    "        images.append(image)\n",
    "    batch[\"image\"] = images\n",
    "    return batch\n",
    "\n",
    "dset = datasets.Dataset.from_pandas(val_df)\n",
    "dset = dset.with_transform(invalid_images_as_none)\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, prefetch_factor=8, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "for i, batch in tqdm(enumerate(loader)):\n",
    "    imgs = []\n",
    "    for i, img in enumerate(batch['image']):\n",
    "        if img is not None:\n",
    "            if img.size[0] < 50 or img.size[1] < 50:\n",
    "                continue\n",
    "            imgs.append(img)\n",
    "            cc3m_val_images_filt.append(batch['image_url'][i])\n",
    "            cc3m_val_caption.append(batch['caption'][i])\n",
    "    \n",
    "    img_embeds = model.encode(imgs, batch_size=bs)\n",
    "    for img_emb in img_embeds:\n",
    "        cc3m_val_images_embed.append(img_emb)\n",
    "\n",
    "    if i == len(loader) - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02360392-8061-4cc9-9fdd-a33883f5de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10978 10978 10978\n"
     ]
    }
   ],
   "source": [
    "print(len(cc3m_val_images_embed), len(cc3m_val_images_filt), len(cc3m_val_caption), flush=True)\n",
    "pickle.dump((cc3m_val_images_filt, cc3m_val_images_embed, cc3m_val_caption, []), open('./cc3m_val.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056ed16-5f55-4a77-b095-9c3c8d934988",
   "metadata": {},
   "source": [
    " ### Extract CC3M Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d337f109-728e-4da7-b0f9-cfa1d3194d12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "0it [00:00, ?it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "4it [00:43,  6.95s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "46it [01:45,  1.69s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "147it [03:51,  1.21it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "204it [04:47,  1.35it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "268it [07:05,  1.17it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "329it [08:13,  1.56it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "332it [08:15,  1.42it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "794it [15:59,  1.34it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "833it [16:27,  1.50it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "958it [18:26,  1.23it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "971it [18:36,  1.41it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "978it [18:57,  1.53s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1228it [22:43,  1.45it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1352it [24:41,  1.15it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1423it [26:01,  2.87s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1652it [30:20,  1.29it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1677it [30:40,  1.13it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1679it [30:41,  1.19it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "1680it [30:56,  5.02s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1722it [31:29,  1.23it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "1857it [33:42,  1.31it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (93950400 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "1862it [34:58,  5.99s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "1869it [35:03,  1.14s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2129it [39:09,  1.26it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2172it [39:45,  1.00s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2177it [39:49,  1.22it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2227it [40:43,  1.13it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2241it [40:54,  1.09it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2395it [43:37,  1.56it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2542it [45:57,  1.30it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2881it [51:15,  1.18it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "3076it [54:28,  2.69s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "3237it [56:47,  1.25it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "3433it [59:38,  1.52it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (107736028 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "3559it [1:01:44,  1.65it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "5973it [1:37:08,  1.30it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "6005it [1:37:42,  1.26it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "6307it [1:42:03,  1.64it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "6442it [1:44:04,  1.37it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "6547it [1:45:39,  1.40it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "6762it [1:48:49,  1.37it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "6890it [1:50:43,  1.57it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "7349it [1:57:42,  1.39it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "7535it [2:00:28,  1.44s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "7669it [2:02:23,  1.25it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "7895it [2:05:39,  1.31it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "8205it [2:10:16,  1.61it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (136901120 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "8934it [2:21:08,  1.37it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "9258it [2:26:04,  1.43it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "9400it [2:28:23,  1.07it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "11280it [2:56:48,  1.31it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "11455it [2:59:30,  1.49it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "11562it [3:01:03,  1.18it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n",
      "12464it [3:14:54,  1.27s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "15093it [3:54:35,  1.39it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "15530it [4:00:57,  1.43it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "16371it [4:13:47,  1.23it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "16414it [4:14:18,  1.23it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:628: UserWarning: Metadata Warning, tag 45057 had too many entries: 2, expected 1\n",
      "  warnings.warn(\n",
      "18499it [4:45:51,  1.41it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (168750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "24958it [6:21:40,  1.42it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "25661it [6:32:15,  1.25it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "25898it [6:35:39,  1.32it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "26142it [6:39:18,  1.23it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "26430it [6:43:39,  1.53it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "28714it [7:17:27,  1.65it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (168750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "30158it [7:38:55,  1.30it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "31022it [7:51:49,  1.57s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "31153it [7:53:44,  1.13it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "32053it [8:06:59,  1.33it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "34196it [8:38:57,  1.22it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "36248it [9:09:24,  1.50it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (149962000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "38333it [9:43:42,  1.45s/it]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "38407it [9:44:43,  1.28it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "38839it [9:50:53,  1.34it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "42444it [10:44:46,  1.19it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "47258it [12:11:03,  1.39it/s] /home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "48555it [12:31:13,  1.31it/s]/home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/Image.py:2896: DecompressionBombWarning: Image size (144000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "49554it [13:00:28,  1.50it/s] /home/samuel/anaconda2/envs/env_instruct_align/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "51849it [13:34:47,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2d 3h 9min 50s, sys: 4h 29min 22s, total: 2d 7h 39min 12s\n",
      "Wall time: 13h 34min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract Text & Image Features from CC3M\n",
    "bs = 64\n",
    "cc3m_trn_images_embed = []\n",
    "cc3m_trn_images_filt = []\n",
    "cc3m_trn_caption = []\n",
    "\n",
    "def invalid_images_as_none(batch):\n",
    "    images = []\n",
    "    for image_url in batch[\"image_url\"]:\n",
    "        try:\n",
    "            image = Image.open(requests.get(image_url, stream=True, timeout=8).raw).convert('RGB')\n",
    "        except Exception:\n",
    "            image = None\n",
    "        images.append(image)\n",
    "    batch[\"image\"] = images\n",
    "    return batch\n",
    "\n",
    "dset = datasets.Dataset.from_pandas(trn_df)\n",
    "dset = dset.with_transform(invalid_images_as_none)\n",
    "\n",
    "loader = DataLoader(dset, batch_size=bs, num_workers=bs, prefetch_factor=8, collate_fn=lambda x: {k: [row[k] for row in x] for k in x[0]})\n",
    "for i, batch in tqdm(enumerate(loader)):\n",
    "    imgs = []\n",
    "    for i, img in enumerate(batch['image']):\n",
    "        if img is not None:\n",
    "            if img.size[0] < 50 or img.size[1] < 50:\n",
    "                continue\n",
    "            imgs.append(img)\n",
    "            cc3m_trn_images_filt.append(batch['image_url'][i])\n",
    "            cc3m_trn_caption.append(batch['caption'][i])\n",
    "    \n",
    "    img_embeds = model.encode(imgs, batch_size=bs)\n",
    "    for img_emb in img_embeds:\n",
    "        cc3m_trn_images_embed.append(img_emb)\n",
    "        \n",
    "    if i == len(loader) - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f11995a-b2ba-4a5d-bf34-c56bd906cffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292954 2292954 2292954\n"
     ]
    }
   ],
   "source": [
    "print(len(cc3m_trn_images_embed), len(cc3m_trn_images_filt), len(cc3m_trn_caption), flush=True)\n",
    "pickle.dump((cc3m_trn_images_filt, cc3m_trn_images_embed, cc3m_trn_caption, []), open('./cc3m_trn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afd6e0-dfd7-450e-ae94-0e6031320710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_instruct_align)",
   "language": "python",
   "name": "env_instruct_align"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
