{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343832e-8f44-4be6-bb24-b5fbf336728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%cd ~\n",
    "if not os.path.exists(\"LLaVA-NeXT\"):\n",
    "    !git clone https://github.com/LLaVA-VL/LLaVA-NeXT\n",
    "%cd LLaVA-NeXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840d465-6622-490a-8c80-3191fc8ad349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.constants import IGNORE_INDEX, DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX\n",
    "from typing import Dict\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e10ec-6fee-4528-a764-a23c3622253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('worldcuisines/food-kb', '', split='main')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f92fb7-d446-41fd-898e-eba8071849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sea_filter(row):\n",
    "    SEA_REGION = \"South Eastern Asia\"\n",
    "    for i in range(1,6):\n",
    "        if row[f'region{i}'] == SEA_REGION:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "dataset = dataset.filter(sea_filter)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74917f73-c904-4fe3-9f41-7be9e0e2200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_prompt = '''Write a caption in English for an image that may include culturally significant objects or elements from Southeast Asia.  \n",
    "The caption should specifically name Southeast Asian cultural items, such as cuisine, traditions, landmarks, or other related elements if they appear in the image.\n",
    "The caption should be concise, consisting of 3 to 5 sentences.'''\n",
    "save_path= \"pangea_worldcuisine_en_result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681abb3c-fcaf-4fac-8377-6ba0af8a7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'neulab/Pangea-7B'\n",
    "model_name = 'Pangea-7B-qwen'\n",
    "args = {\"multimodal\": True}\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, None, model_name, torch_dtype=\"float16\", **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374457fd-7c5c-4f94-bdae-080c9ee4f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_qwen(sources, tokenizer: transformers.PreTrainedTokenizer, has_image: bool = False, max_len=512, system_message: str = \"You are a helpful assistant.\") -> Dict:\n",
    "    roles = {\"human\": \"<|im_start|>user\", \"gpt\": \"<|im_start|>assistant\"}\n",
    "    im_start, im_end = tokenizer.additional_special_tokens_ids\n",
    "    nl_tokens = tokenizer(\"\\n\").input_ids\n",
    "    _system = tokenizer(\"system\").input_ids + nl_tokens\n",
    "    _user = tokenizer(\"user\").input_ids + nl_tokens\n",
    "    _assistant = tokenizer(\"assistant\").input_ids + nl_tokens\n",
    "    input_ids = []\n",
    "    source = sources\n",
    "    if roles[source[0][\"from\"]] != roles[\"human\"]: source = source[1:]\n",
    "    input_id, target = [], []\n",
    "    system = [im_start] + _system + tokenizer(system_message).input_ids + [im_end] + nl_tokens\n",
    "    input_id += system\n",
    "    target += [im_start] + [IGNORE_INDEX] * (len(system) - 3) + [im_end] + nl_tokens\n",
    "    assert len(input_id) == len(target)\n",
    "    for j, sentence in enumerate(source):\n",
    "        role = roles[sentence[\"from\"]]\n",
    "        if has_image and sentence[\"value\"] is not None and \"<image>\" in sentence[\"value\"]:\n",
    "            num_image = len(re.findall(DEFAULT_IMAGE_TOKEN, sentence[\"value\"]))\n",
    "            texts = sentence[\"value\"].split('<image>')\n",
    "            _input_id = tokenizer(role).input_ids + nl_tokens \n",
    "            for i,text in enumerate(texts):\n",
    "                _input_id += tokenizer(text).input_ids \n",
    "                if i<len(texts)-1: _input_id += [IMAGE_TOKEN_INDEX] + nl_tokens\n",
    "            _input_id += [im_end] + nl_tokens\n",
    "            assert sum([i==IMAGE_TOKEN_INDEX for i in _input_id])==num_image\n",
    "        else:\n",
    "            if sentence[\"value\"] is None: _input_id = tokenizer(role).input_ids + nl_tokens\n",
    "            else: _input_id = tokenizer(role).input_ids + nl_tokens + tokenizer(sentence[\"value\"]).input_ids + [im_end] + nl_tokens\n",
    "        input_id += _input_id\n",
    "    input_ids.append(input_id)\n",
    "    return torch.tensor(input_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9913a2-aec5-4a19-9390-efaa804990a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(image, prompt):\n",
    "    image_tensors = []\n",
    "    prompt = \"<image>\\n\" + prompt\n",
    "\n",
    "    image_tensor = image_processor.preprocess(image, return_tensors='pt')['pixel_values']\n",
    "    image_tensors.append(image_tensor.half().cuda())\n",
    "    input_ids = preprocess_qwen([{'from': 'human', 'value': prompt},{'from': 'gpt','value': None}], tokenizer, has_image=True).cuda()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            images=image_tensors,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "            max_new_tokens=512,\n",
    "            use_cache=True\n",
    "        )\n",
    "    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "    outputs = outputs.strip()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8f50b5-4436-4051-9435-9fe38c0cbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(save_path, json_obj):\n",
    "    if not os.path.exists(save_path):\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump([json_obj], f, indent=4)\n",
    "    else:\n",
    "        with open(save_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        data.append(json_obj)\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d9d69-7cf6-4b61-b432-c240659f0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset)), desc=\"Progess\"):\n",
    "    row = dataset[i]\n",
    "    cuisines = row['cuisines']\n",
    "    name = row['name']\n",
    "    \n",
    "    for i in range(1, 9):\n",
    "        image_key = f\"image{i}\"  \n",
    "        image = row[image_key]\n",
    "\n",
    "        if image is not None:\n",
    "            url_key = image_key + \"_url\"\n",
    "            image_url = row[url_key]\n",
    "            image_url = image_url.replace(\"?download\", \"\")\n",
    "            caption = get_caption(image, en_prompt)\n",
    "            caption = caption.replace('Caption: ', '').replace('\"','')\n",
    "\n",
    "            json_obj={\"name\":name,\n",
    "                      \"cuisines\":cuisines,\n",
    "                      \"image_url\":image_url,\n",
    "                      \"caption\":caption}\n",
    "            \n",
    "            save_to_json(save_path, json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51514c11-8567-4f57-aa72-787e6b26a419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
