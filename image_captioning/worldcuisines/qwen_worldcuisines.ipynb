{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840d465-6622-490a-8c80-3191fc8ad349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e10ec-6fee-4528-a764-a23c3622253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('worldcuisines/food-kb', '', split='main')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f92fb7-d446-41fd-898e-eba8071849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sea_filter(row):\n",
    "    SEA_REGION = \"South Eastern Asia\"\n",
    "    for i in range(1,6):\n",
    "        if row[f'region{i}'] == SEA_REGION:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "dataset = dataset.filter(sea_filter)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74917f73-c904-4fe3-9f41-7be9e0e2200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_prompt = '''Write a caption in English for an image that may include culturally significant objects or elements from Southeast Asia.  \n",
    "The caption should specifically name Southeast Asian cultural items, such as cuisine, traditions, landmarks, or other related elements if they appear in the image.\n",
    "The caption should be concise, consisting of 3 to 5 sentences.'''\n",
    "save_path= \"qwen_worldcuisine_en_result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681abb3c-fcaf-4fac-8377-6ba0af8a7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", torch_dtype=torch.float16, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb5cb6a-f581-41f8-9f81-499b030004c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_message(caption_list, prompt):\n",
    "    transformed_objs = []\n",
    "    for obj in caption_list:\n",
    "        new_obj = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": obj[\"image\"]},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "        transformed_objs.append(new_obj)\n",
    "    return transformed_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9913a2-aec5-4a19-9390-efaa804990a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption_batch(caption_list, prompt):\n",
    "    messages = concat_message(caption_list, en_prompt)\n",
    "    texts = [\n",
    "        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
    "        for msg in messages\n",
    "    ]\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Batch Inference\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_texts = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b913ead-1d58-44ad-9391-8fefb51f5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(image, prompt):\n",
    "    messages =[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8f50b5-4436-4051-9435-9fe38c0cbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(save_path, json_obj):\n",
    "    if not os.path.exists(save_path):\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump([json_obj], f, indent=4)\n",
    "    else:\n",
    "        with open(save_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        data.append(json_obj)\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4afd23-d995-4e6d-ac88-f66518ec1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset)), desc=\"Progess\"):\n",
    "    row = dataset[i]\n",
    "    caption_list=[]\n",
    "    cuisines = row['cuisines']\n",
    "    name = row['name']\n",
    "    \n",
    "    for i in range(1, 9):\n",
    "        image_key = f\"image{i}\"  \n",
    "        image = row[image_key]\n",
    "\n",
    "        if image is not None:\n",
    "            url_key = image_key + \"_url\"\n",
    "            image_url = row[url_key]\n",
    "            image_url = image_url.replace(\"?download\", \"\")\n",
    "\n",
    "            url_key = image_key + \"_url\"\n",
    "            image_url = row[url_key]\n",
    "            image_url = image_url.replace(\"?download\", \"\")\n",
    "            caption = get_caption(image, en_prompt)\n",
    "\n",
    "            json_obj={\"name\":name,\n",
    "                      \"cuisines\":cuisines,\n",
    "                      \"image_url\":image_url,\n",
    "                      \"caption\":caption}\n",
    "            \n",
    "            save_to_json(save_path, json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d9d69-7cf6-4b61-b432-c240659f0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(dataset)), desc=\"Progess\"):\n",
    "#     row = dataset[i]\n",
    "#     caption_list=[]\n",
    "#     cuisines = row['cuisines']\n",
    "#     name = row['name']\n",
    "    \n",
    "#     for i in range(1, 9):\n",
    "#         image_key = f\"image{i}\"  \n",
    "#         image = row[image_key]\n",
    "\n",
    "#         if image is not None:\n",
    "#             url_key = image_key + \"_url\"\n",
    "#             image_url = row[url_key]\n",
    "#             image_url = image_url.replace(\"?download\", \"\")\n",
    "\n",
    "#             json_obj={\"name\":name,\n",
    "#                       \"cuisines\":cuisines,\n",
    "#                       \"image_url\":image_url,\n",
    "#                       \"image\":image,\n",
    "#                       \"caption\":\"\"}\n",
    "#             caption_list.append(json_obj)\n",
    "\n",
    "#     caption_result_list = get_caption_batch(caption_list, en_prompt)\n",
    "\n",
    "#     for i in range(len(caption_result_list)):\n",
    "#         del caption_list[i]['image']\n",
    "#         caption_list[i]['caption']=caption_result_list[i]\n",
    "#         save_to_json(save_path, caption_list[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051755d-8686-4150-a3fa-f1df3b34e6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
