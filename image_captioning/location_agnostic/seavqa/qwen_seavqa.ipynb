{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840d465-6622-490a-8c80-3191fc8ad349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699e10ec-6fee-4528-a764-a23c3622253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_image_iterator(root_dir):\n",
    "    images_dir = os.path.join(root_dir, \"images\")\n",
    "\n",
    "    for json_file in os.listdir(root_dir):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            json_path = os.path.join(root_dir, json_file)\n",
    "            \n",
    "            with open(json_path, \"r\") as f:\n",
    "                data_list = json.load(f)\n",
    "\n",
    "            file_name = os.path.splitext(json_file)[0]\n",
    "            \n",
    "            for data in data_list:\n",
    "                image_filename = data[\"image_path\"].split(\"/\")[-1]\n",
    "                \n",
    "                image_found = False\n",
    "                for root, dirs, files in os.walk(images_dir):\n",
    "                    if image_filename in files:\n",
    "                        image_path = os.path.join(root, image_filename)\n",
    "                        \n",
    "                        try:\n",
    "                            # image = Image.open(image_path)\n",
    "                            yield file_name, data, image_path \n",
    "                            image_found = True\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error opening image {image_path}: {e}\")\n",
    "                        break\n",
    "                \n",
    "                if not image_found:\n",
    "                    print(f\"Image not found for entry in {json_file}: {image_filename}\")\n",
    "                    yield file_name, data, None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74917f73-c904-4fe3-9f41-7be9e0e2200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_prompt = '''Write a caption in English for an image that may include culturally significant objects or elements from Southeast Asia.  \n",
    "The caption should specifically name Southeast Asian cultural items, such as cuisine, traditions, landmarks, or other related elements if they appear in the image.\n",
    "The caption should be concise, consisting of 3 to 5 sentences.'''\n",
    "save_path= \"qwen_seavqa_en_result.json\"\n",
    "image_root_path = r\"/root/filter_sea_vqa_final/filter_sea_vqa_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681abb3c-fcaf-4fac-8377-6ba0af8a7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", torch_dtype=torch.float16, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb5cb6a-f581-41f8-9f81-499b030004c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_message(caption_list, prompt):\n",
    "    transformed_objs = []\n",
    "    for obj in caption_list:\n",
    "        new_obj = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": obj[\"image\"]},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "        transformed_objs.append(new_obj)\n",
    "    return transformed_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9913a2-aec5-4a19-9390-efaa804990a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption_batch(caption_list, prompt):\n",
    "    messages = concat_message(caption_list, en_prompt)\n",
    "    texts = [\n",
    "        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
    "        for msg in messages\n",
    "    ]\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Batch Inference\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_texts = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b913ead-1d58-44ad-9391-8fefb51f5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(image, prompt):\n",
    "    messages =[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8f50b5-4436-4051-9435-9fe38c0cbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(save_path, json_obj):\n",
    "    if not os.path.exists(save_path):\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump([json_obj], f, indent=4)\n",
    "    else:\n",
    "        with open(save_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        data.append(json_obj)\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4afd23-d995-4e6d-ac88-f66518ec1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = json_image_iterator(image_root_path)\n",
    "items = list(iterator)\n",
    "\n",
    "for country, data, image in tqdm(items, desc=\"Progess\"):\n",
    "    caption = get_caption(image, en_prompt)\n",
    "\n",
    "    json_obj={\"name\":data[\"culture_name\"],\n",
    "              \"country\":country,\n",
    "              \"image_url\":data[\"image_path\"],\n",
    "              \"gt_caption\":data[\"gt_caption\"],\n",
    "              \"caption\":caption}\n",
    "            \n",
    "    save_to_json(save_path, json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051755d-8686-4150-a3fa-f1df3b34e6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
