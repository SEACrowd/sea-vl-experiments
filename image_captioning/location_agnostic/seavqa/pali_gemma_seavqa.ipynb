{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840d465-6622-490a-8c80-3191fc8ad349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    PaliGemmaProcessor,\n",
    "    PaliGemmaForConditionalGeneration,\n",
    ")\n",
    "from transformers.image_utils import load_image\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b059ee8d-554c-41e6-9586-1955cb681d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_image_iterator(root_dir):\n",
    "    images_dir = os.path.join(root_dir, \"images\")\n",
    "\n",
    "    for json_file in os.listdir(root_dir):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            json_path = os.path.join(root_dir, json_file)\n",
    "            \n",
    "            with open(json_path, \"r\") as f:\n",
    "                data_list = json.load(f)\n",
    "\n",
    "            file_name = os.path.splitext(json_file)[0]\n",
    "            \n",
    "            for data in data_list:\n",
    "                image_filename = data[\"image_path\"].split(\"/\")[-1]\n",
    "                \n",
    "                image_found = False\n",
    "                for root, dirs, files in os.walk(images_dir):\n",
    "                    if image_filename in files:\n",
    "                        image_path = os.path.join(root, image_filename)\n",
    "                        \n",
    "                        try:\n",
    "                            # image = Image.open(image_path)\n",
    "                            yield file_name, data, image_path \n",
    "                            image_found = True\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error opening image {image_path}: {e}\")\n",
    "                        break\n",
    "                \n",
    "                if not image_found:\n",
    "                    print(f\"Image not found for entry in {json_file}: {image_filename}\")\n",
    "                    yield file_name, data, None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74917f73-c904-4fe3-9f41-7be9e0e2200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_prompt = '''Write a caption in English for an image that may include culturally significant objects or elements from Southeast Asia.  \n",
    "The caption should specifically name Southeast Asian cultural items, such as cuisine, traditions, landmarks, or other related elements if they appear in the image.\n",
    "The caption should be concise, consisting of 3 to 5 sentences.'''\n",
    "save_path= \"pali_gemma_seavqa_en_result.json\"\n",
    "image_root_path = r\"/root/filter_sea_vqa_final/filter_sea_vqa_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681abb3c-fcaf-4fac-8377-6ba0af8a7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/paligemma2-10b-ft-docci-448\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\").eval()\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9913a2-aec5-4a19-9390-efaa804990a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(image, prompt):\n",
    "    image = load_image(image)\n",
    "    model_inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(torch.float16).to(model.device)\n",
    "    input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "    with torch.inference_mode():\n",
    "        generation = model.generate(**model_inputs, max_new_tokens=512, do_sample=False, num_beams=1)\n",
    "        generation = generation[0][input_len:]\n",
    "        decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8f50b5-4436-4051-9435-9fe38c0cbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(save_path, json_obj):\n",
    "    if not os.path.exists(save_path):\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump([json_obj], f, indent=4)\n",
    "    else:\n",
    "        with open(save_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        data.append(json_obj)\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acec793-3604-45af-a306-29a8e6d0d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = json_image_iterator(image_root_path)\n",
    "items = list(iterator)\n",
    "\n",
    "for country, data, image in tqdm(items, desc=\"Progess\"):\n",
    "    caption = get_caption(image, en_prompt)\n",
    "    \n",
    "    json_obj={\"name\":data[\"culture_name\"],\n",
    "              \"country\":country,\n",
    "              \"image_url\":data[\"image_path\"],\n",
    "              \"gt_caption\":data[\"gt_caption\"],\n",
    "              \"caption\":caption}\n",
    "            \n",
    "    save_to_json(save_path, json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eaba34-11b5-4628-82dd-7672e6b16fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
